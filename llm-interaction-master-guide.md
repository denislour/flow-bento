# ğŸ¤– Flow-Bento LLM Interaction Master Guide

## ğŸ¯ Core LLM Behaviors

### ğŸ“– **Intelligent File Reading Protocol**

When LLM encounters file reading tasks:

#### Phase 1: Pre-Read Analysis
```
1. ğŸ” ANALYZE: What information is needed from this file?
2. ğŸ“Š ASSESS: File size and complexity estimation
3. ğŸ¯ STRATEGY: Choose optimal reading approach
```

#### Phase 2: Smart Reading Strategy
```
ğŸ”¬ SMALL FILES (<500 lines):
â†’ Read entire file with dependencies context

ğŸ“š MEDIUM FILES (500-2000 lines):
â†’ Read in logical sections (classes, functions)
â†’ Use symbol overview first, then targeted reads

ğŸ“– LARGE FILES (2000+ lines):
â†’ Symbol overview â†’ Target specific sections
â†’ Read only relevant portions based on task
```

#### Phase 3: Dependency Context Building
```
ğŸ”— ALWAYS after reading a file:
1. Identify imported modules/dependencies
2. Map function/class relationships
3. Note external API calls or references
4. Store architectural insights in memory
```

### ğŸ” **Advanced Symbol Discovery Protocol**

#### Smart Search Sequence:
```
ğŸ¯ USER REQUEST: "Find where method login is used"

ğŸ“‹ LLM AUTO-SEQUENCE:
1. find-symbol.md â†’ Locate login method definition
2. find-references.md â†’ Find all usage locations  
3. read-file.md â†’ Read each usage context
4. symbols-overview.md â†’ Understand calling patterns
5. write-memory.md â†’ Store usage patterns discovered
```

#### Cross-Reference Analysis:
```
ğŸ§¬ DEEP ANALYSIS PATTERN:
1. ğŸ“ LOCATE: Find primary symbol
2. ğŸŒ MAP: Discover all references and dependencies
3. ğŸ“ˆ ANALYZE: Understanding usage patterns and flow
4. ğŸ§  SYNTHESIZE: Create comprehensive understanding
5. ğŸ’¾ STORE: Save architectural insights
```

### ğŸ”„ **Intelligent Workflow Chaining**

#### Decision Tree for Complex Tasks:
```
â“ "Modify user authentication system"

ğŸ¤– LLM DECISION PROCESS:
â”Œâ”€ Is this a SEARCH task? â†’ find-symbol workflows
â”œâ”€ Is this a MODIFY task? â†’ read â†’ analyze â†’ replace
â”œâ”€ Is this COMPLEX? â†’ break into sub-tasks
â””â”€ Does it need VALIDATION? â†’ thinking workflows

ğŸ”— AUTO-CHAIN RESULT:
1. think-about-task-adherence.md (understand scope)
2. find-symbol.md (locate auth components) 
3. find-references.md (map all usage)
4. read-file.md (understand current implementation)
5. symbols-overview.md (grasp architecture)
6. replace-symbol.md (implement changes)
7. think-about-whether-you-are-done.md (validate)
8. write-memory.md (document changes)
```

### ğŸ§  **Context-Aware Memory Management**

#### Automatic Memory Creation Triggers:
```
ğŸ¯ ALWAYS CREATE MEMORY WHEN:
- ğŸ—ï¸ Discovering new architectural patterns
- ğŸ”— Finding complex dependency relationships  
- ğŸ¨ Learning user's coding style preferences
- ğŸ› Identifying common bug patterns
- âš¡ Finding performance optimization opportunities
- ğŸ”’ Discovering security-related code patterns
```

#### Memory Categorization Strategy:
```
ğŸ“š MEMORY CATEGORIES:
â”œâ”€â”€ ğŸ—ï¸ architecture_insights
â”œâ”€â”€ ğŸ”— dependency_maps  
â”œâ”€â”€ ğŸ¨ coding_patterns
â”œâ”€â”€ ğŸ› bug_patterns
â”œâ”€â”€ âš¡ performance_notes
â”œâ”€â”€ ğŸ”’ security_findings
â””â”€â”€ ğŸ‘¤ user_preferences
```

## ğŸš€ **Advanced LLM Automation Rules**

### ğŸ¯ **Smart Context Building**
```
FOR EVERY DEVELOPMENT TASK:
1. ğŸ“Š Build dependency map first
2. ğŸ§  Access relevant memories  
3. ğŸ¯ Apply appropriate workflow chain
4. ğŸ’¾ Store new insights discovered
5. âœ… Validate with thinking workflows
```

### ğŸ”„ **Failure Recovery Protocol**
```
IF WORKFLOW FAILS:
1. ğŸ›‘ STOP current chain
2. ğŸ” ANALYZE failure point
3. ğŸ“– CHECK alternative workflows
4. ğŸ”„ RETRY with adjusted approach
5. ğŸ’¾ STORE recovery pattern for future
```

### âš¡ **Performance Optimization**
```
ğŸš€ SPEED OPTIMIZATIONS:
- ğŸ’¾ Cache frequently accessed symbol locations
- ğŸ§  Remember user's common request patterns
- ğŸ”— Pre-load related workflows for complex tasks
- ğŸ“Š Build incremental project understanding
```

---

**ğŸ± This master guide transforms LLMs into intelligent, context-aware development partners that learn and adapt with every interaction!**